# LLMs
LLM papers

## 综述论文

|论文|地址|项目|解读文章|
|--|--|--|--|
|A Survey of Large Language Models|[arxiv](https://arxiv.org/abs/2303.18223)|[github](https://github.com/RUCAIBox/LLMSurvey)|[链接](https://zhuanlan.zhihu.com/p/630203554)|
|A Survey on Multimodal Large Language Models|[arxiv](https://arxiv.org/abs/2306.13549)|[github](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)|[链接](https://zhuanlan.zhihu.com/p/648924161)|
|The (R)Evolution of Multimodal Large Language Models: A Survey|[arxiv](https://arxiv.org/abs/2402.12451)|--|--|
|Large Language Models: A Survey|[arxiv](https://arxiv.org/abs/2402.06196)|--|[链接](https://zhuanlan.zhihu.com/p/683133002)|
|Domain Specialization as the Key to Make Large Language Models Disruptive: A Comprehensive Survey|[arxiv](https://arxiv.org/abs/2305.18703)|--|--|
|Scientific Large Language Models: A Survey on Biological & Chemical Domains|[arxiv](https://arxiv.org/abs/2401.14656)|[githup](https://github.com/HICAI-ZJU/Scientific-LLM-Survey)|--|
|Data Management For Large Language Models: A Survey|[arxiv](https://arxiv.org/abs/2312.01700)|[githup](https://github.com/ZigeW/data_management_LLM)|--|
|If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents|[arxiv](https://arxiv.org/abs/2401.00812)|--|--|
|Large Language Models on Graphs: A Comprehensive Survey|[arxiv](https://arxiv.org/abs/2312.02783)|[gitcode](https://gitcode.com/petergriffinjin/awesome-language-model-on-graphs/overview?utm_source=csdn_github_accelerator&isLogin=1)|--|
|A Survey on Hardware Accelerators for Large Language Models|[arxiv](https://arxiv.org/abs/2401.09890)|--|--|
|A Survey on Multimodal Large Language Models for Autonomous Driving|[arxiv](https://arxiv.org/abs/2311.12320)|--|--|
|A Survey on Evaluation of Large Language Models|[arxiv](https://arxiv.org/abs/2307.03109)|--|[链接](https://zhuanlan.zhihu.com/p/643086466)|
|Efficient Large Language Models: A Survey|[arxiv](https://arxiv.org/abs/2312.03863)|[github](https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey)|[链接](https://mp.weixin.qq.com/s/_CS5qcCO_86AMoj0GnmmUw)|
|Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey|[arxiv](https://arxiv.org/abs/2311.12351)|[github](https://github.com/Strivin0311/long-llms-learning)|[链接](https://mp.weixin.qq.com/s/VrV3E_SKTbpjJBfFyirvhA)|
|The Rise and Potential of Large Language Model Based Agents: A Survey|[arxiv](https://arxiv.org/abs/2309.07864)|--|[链接](https://mp.weixin.qq.com/s/BiW86exdIr7yuy7cdaFbPQ)|
|A Survey on Knowledge Distillation of Large Language Models|[arxiv](https://arxiv.org/abs/2402.13116)|[github](https://mp.weixin.qq.com/s/schQHpNXk1PgFoQ1myac8Q)|[链接](https://mp.weixin.qq.com/s/schQHpNXk1PgFoQ1myac8Q)|
|Large Language Models for Time Series: A Survey|[arxiv](https://arxiv.org/abs/2402.01801)|[github](https://github.com/xiyuanzh/awesome-llm-time-series)|[链接](https://mp.weixin.qq.com/s/xXgez0eCmlHC3KuD1BynCw)|
|MM-LLMs: Recent Advances in MultiModal Large Language Models|[arxiv](https://arxiv.org/abs/2401.13601)|[github](https://mm-llms.github.io)|[链接](https://mp.weixin.qq.com/s/eC5qSI7QCIJoLOscpNB5fQ)|

## 最新论文

|论文|地址|
|--|--|
|PALO: A Polyglot Large Multimodal Model for 5B People|[arxiv](https://arxiv.org/list/cs/pastweek?skip=0&show=25)|
|RelayAttention for Efficient Large Language Model Serving with Long System Prompts|[arxiv](https://arxiv.org/abs/2402.14808)|
|Identifying Multiple Personalities in Large Language Models with External Evaluation|[arxiv](https://arxiv.org/abs/2402.14805)|
|Not All Experts are Equal: Efficient Expert Pruning and Skipping for Mixture-of-Experts Large Language Models|[arxiv](https://arxiv.org/abs/2402.14800)|
|Zero-shot cross-lingual transfer in instruction tuning of large language model|[arxiv](https://arxiv.org/abs/2402.14778)|
|DualFocus: Integrating Macro and Micro Perspectives in Multi-modal Large Language Models|[arxiv](https://arxiv.org/abs/2402.14767)|
|MT-Bench-101: A Fine-Grained Benchmark for Evaluating Large Language Models in Multi-Turn Dialogues|[arxiv](https://arxiv.org/abs/2402.14762)|
|Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation|[arxiv](https://arxiv.org/abs/2402.14744)|
|Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models |[arxiv](https://arxiv.org/abs/2402.14714)|
|IEPile: Unearthing Large-Scale Schema-Based Information Extraction Corpus|[arxiv](https://arxiv.org/abs/2402.14710)|
|Unveiling Linguistic Regions in Large Language Models|[arxiv](https://arxiv.org/abs/2402.14700)|
|UFO: a Unified and Flexible Framework for Evaluating Factuality of Large Language Models|[arxiv](https://arxiv.org/abs/2402.14690)|
|Visual Hallucinations of Multi-modal Large Language Models|[arxiv](https://arxiv.org/abs/2402.14683)|
|Is Cognition and Action Consistent or Not: Investigating Large Language Model's Personality|[arxiv](https://arxiv.org/abs/2402.14679)|
|Automating Psychological Hypothesis Generation with AI: Large Language Models Meet Causal Graph|[arxiv](https://arxiv.org/abs/2402.14424)|
|Towards Unified Task Embeddings Across Multiple Models: Bridging the Gap for Prompt-Based Large Language Models and Beyond|[arxiv](https://arxiv.org/abs/2402.14522)|
|LLM-DA: Data Augmentation via Large Language Models for Few-Shot Named Entity Recognition|[arxiv](https://arxiv.org/abs/2402.14568)|
|Improving Assessment of Tutoring Practices using Retrieval-Augmented Generation|[arxiv](https://arxiv.org/abs/2402.14594)|
|ConceptMath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models|[arxiv](https://arxiv.org/abs/2402.14660)|
|Bayesian Off-Policy Evaluation and Learning for Large Action Spaces|[arxiv](https://arxiv.org/abs/2402.14664)|
|Automating Psychological Hypothesis Generation with AI: Large Language Models Meet Causal Graph|[arxiv](https://arxiv.org/abs/2402.14424)|
|From Large to Small Datasets: Size Generalization for Clustering Algorithm Selection|[arxiv](https://arxiv.org/abs/2402.14332)|
|Rule or Story, Which is a Better Commonsense Expression for Talking with Large Language Models?|[arxiv](https://arxiv.org/abs/2402.14355)|
|OpenTab: Advancing Large Language Models as Open-domain Table Reasoners|[arxiv](https://arxiv.org/abs/2402.14361)|
|Scalable and Provably Fair Exposure Control for Large-Scale Recommender Systems|[arxiv](https://arxiv.org/abs/2402.14369)|
|Small Language Model Is a Good Guide for Large Language Model in Chinese Entity Relation Extraction|[arxiv](https://arxiv.org/abs/2402.14373)|
|Enhancing Temporal Knowledge Graph Forecasting with Large Language Models via Chain-of-History Reasoning|[arxiv](https://arxiv.org/abs/2402.14382)|
|On the Tip of the Tongue: Analyzing Conceptual Representation in Large Language Models with Reverse-Dictionary Probe|[arxiv](https://arxiv.org/abs/2402.14404)|
|GenSERP: Large Language Models for Whole Page Presentation|[arxiv](https://arxiv.org/abs/2402.14301)|
|Mitigating Biases of Large Language Models in Stance Detection with Calibration|[arxiv](https://arxiv.org/abs/2402.14296)|
|Leveraging Large Language Models for Concept Graph Recovery and Question Answering in NLP Education|[arxiv](https://arxiv.org/abs/2402.14293)|
|TinyLLaVA: A Framework of Small-scale Large Multimodal Models|[arxiv](https://arxiv.org/abs/2402.14289)|
|Can Large Language Models Detect Misinformation in Scientific News Reporting?|[arxiv](https://arxiv.org/abs/2402.14268)|
|Enhancing Robotic Manipulation with AI Feedback from Multimodal Large Language Models|[arxiv](https://arxiv.org/abs/2402.14245)|
|FanOutQA: Multi-Hop, Multi-Document Question Answering for Large Language Models|[arxiv](https://arxiv.org/abs/2402.14116)|
|LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons|[arxiv](https://arxiv.org/abs/2402.14086)|
|On Large Visual Language Models for Medical Imaging Analysis: An Empirical Study|[arxiv](https://arxiv.org/abs/2402.14162)|
|MM-Soc: Benchmarking Multimodal Large Language Models in Social Media Platforms|[arxiv](https://arxiv.org/abs/2402.14154)|
|ModSRAM: Algorithm-Hardware Co-Design for Large Number Modular Multiplication in SRAM|[arxiv](https://arxiv.org/abs/2402.14152)|
|Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models|[arxiv](https://arxiv.org/abs/2402.14207)|
|Towards Understanding Counseling Conversations: Domain Knowledge and Large Language Models|[arxiv](https://arxiv.org/abs/2402.14200)|
|Learning to Reduce: Optimal Representations of Structured Data in Prompting Large Language Models|[arxiv](https://arxiv.org/abs/2402.14195)|
|Do Machines and Humans Focus on Similar Code? Exploring Explainability of Large Language Models in Code Summarization|[arxiv](https://arxiv.org/abs/2402.14182)|
|Bangla AI: A Framework for Machine Translation Utilizing Large Language Models for Ethnic Media|[arxiv](https://arxiv.org/abs/2402.14179)|
||[arxiv]()|
||[arxiv]()|
||[arxiv]()|

## 项目链接

|项目|地址|
|--|--|
|LLM-Agents-Papers|[github](https://github.com/AGI-Edgerunners/LLM-Agents-Papers)|
|LLM-eval-survey|[github](https://github.com/MLGroupJLU/LLM-eval-survey)|
|LLMSurvey|[github](https://github.com/RUCAIBox/LLMSurvey)|
|Awesome-Multimodal-Large-Language-Models|[github](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)|
|Scientific-LLM-Survey|[github](https://github.com/HICAI-ZJU/Scientific-LLM-Survey)|
|data_management_LLM|[github](https://github.com/ZigeW/data_management_LLM)|
|Efficient-LLMs-Survey|[github](https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey)|
|peft|[github](https://github.com/huggingface/peft)|
|awesome-llm-list|[github](https://github.com/Barnacle-ai/awesome-llm-list)|
|Awesome-Knowledge-Distillation-of-LLMs|[github](https://github.com/Tebmer/Awesome-Knowledge-Distillation-of-LLMs)|
|Awesome-AGI|[github](https://github.com/ArronAI007/Awesome-AGI)|
|awesome-llm-time-series|[github](https://github.com/xiyuanzh/awesome-llm-time-series)|
|awesome-generative-ai-guide|[github](https://github.com/aishwaryanr/awesome-generative-ai-guide)|

## 博客文章

|文章|地址|
|--|--|
|大语言模型的前世今生|[链接](https://bbs.huaweicloud.com/blogs/416109?utm_source=zhihu&utm_medium=bbs-ex&utm_campaign=other&utm_content=content)|
|万字长文聊聊LLM Agents的现状，问题与未来|[链接](https://mp.weixin.qq.com/s/BiW86exdIr7yuy7cdaFbPQ)|

